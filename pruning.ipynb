{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9eb0eb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, time\n",
    "import torch\n",
    "import torch.nn.utils.prune as prune\n",
    "import torch.nn.functional as F\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer, DataCollatorWithPadding\n",
    "from datasets import load_dataset\n",
    "from evaluate import load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81ce7077",
   "metadata": {},
   "outputs": [],
   "source": [
    "STUDENT_PATH = \"./drive/MyDrive/bert_sst2_student/best_model\"\n",
    "STUDENT_TOKENIZER = \"./drive/MyDrive/bert_sst2_student/tokenizer\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(STUDENT_TOKENIZER)\n",
    "student = AutoModelForSequenceClassification.from_pretrained(STUDENT_PATH)\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "student.to(device)\n",
    "\n",
    "# dataset\n",
    "task = \"sst2\"\n",
    "raw = load_dataset(\"glue\", task)\n",
    "max_len = 128\n",
    "def preprocess(examples):\n",
    "    return tokenizer(examples[\"sentence\"], truncation=True)\n",
    "encoded = raw.map(preprocess, batched=True)\n",
    "encoded = encoded.remove_columns([\"sentence\", \"idx\"])\n",
    "encoded.set_format(type=\"torch\")\n",
    "train_ds = encoded[\"train\"]\n",
    "val_ds = encoded[\"validation\"]\n",
    "data_collator = DataCollatorWithPadding(tokenizer)\n",
    "metric = load(\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac792adc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_parameters(model):\n",
    "    total = sum(p.numel() for p in model.parameters())\n",
    "    nonzero = sum((p != 0).sum().item() for p in model.parameters())\n",
    "    return total, nonzero, 1 - (nonzero/total)\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    preds = logits.argmax(-1)\n",
    "    return {\"accuracy\": metric.compute(predictions=preds, references=labels)[\"accuracy\"]}\n",
    "\n",
    "def evaluate_latency(model, tokenizer, device, max_len=128, N=200):\n",
    "    model.to(device).eval()\n",
    "    sample = tokenizer(\"This is a sample sentence to measure latency.\", return_tensors=\"pt\", max_length=max_len, truncation=True, padding=\"max_length\")\n",
    "    input_ids = sample['input_ids'].to(device)\n",
    "    attention_mask = sample['attention_mask'].to(device)\n",
    "    # warmup\n",
    "    with torch.no_grad():\n",
    "        for _ in range(10):\n",
    "            _ = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "    if device == \"cuda\":\n",
    "        torch.cuda.synchronize()\n",
    "    import time\n",
    "    t0 = time.time()\n",
    "    with torch.no_grad():\n",
    "        for _ in range(N):\n",
    "            _ = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "    if device == \"cuda\":\n",
    "        torch.cuda.synchronize()\n",
    "    t1 = time.time()\n",
    "    return (t1 - t0) / N * 1000  # ms\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07d872f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## unstructured ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "857ff2e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "modules_to_prune = []\n",
    "for name, module in student.named_modules():\n",
    "    if isinstance(module, torch.nn.Linear):\n",
    "        modules_to_prune.append((module, 'weight'))\n",
    "\n",
    "amount = 0.4  # 40% sparsity\n",
    "prune.global_unstructured(\n",
    "    modules_to_prune,\n",
    "    pruning_method=prune.L1Unstructured,\n",
    "    amount=amount,\n",
    ")\n",
    "# check sparsity\n",
    "total, nonzero, sparsity = count_parameters(student)\n",
    "print(f\"Total params: {total:,}, nonzero: {nonzero:,}, global density: {1-sparsity:.3f}, sparsity â‰ˆ {sparsity:.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24bbc29a",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./pruned_student\",\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=64,\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    learning_rate=3e-5,\n",
    "    weight_decay=0.01,\n",
    "    fp16=True,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"accuracy\",\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=student,\n",
    "    args=training_args,\n",
    "    train_dataset=train_ds,\n",
    "    eval_dataset=val_ds,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d3371f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove reparam (makes zeros permanent)\n",
    "for module, _ in modules_to_prune:\n",
    "    try:\n",
    "        prune.remove(module, 'weight')\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "# report\n",
    "total, nonzero, sparsity = count_parameters(student)\n",
    "print(\"After remove():\", total, nonzero, sparsity)\n",
    "print(\"Val eval:\")\n",
    "res = trainer.evaluate()\n",
    "print(res)\n",
    "print(\"Latency (ms):\", evaluate_latency(student, tokenizer, device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "556779db",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_model(\"./drive/MyDrive/pruned_student_unstructured/best_model_40\")\n",
    "# Latency (ms): 5.5631959438323975"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d62d65d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Structured Pruning ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfdb9e62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if method exists\n",
    "print(hasattr(student, \"prune_heads\"))          # True if model supports pruning\n",
    "print(hasattr(student, \"distilbert\"))           # DistilBERT container\n",
    "print(student.distilbert)                       # check attributes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df4430ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_layers = student.config.num_hidden_layers\n",
    "n_heads = student.config.num_attention_heads\n",
    "\n",
    "heads_to_prune = {}\n",
    "for layer in range(n_layers):\n",
    "    # prune first half of heads in each layer\n",
    "    heads_to_prune[layer] = list(range(n_heads // 2))\n",
    "\n",
    "print(\"Heads to prune per layer:\", heads_to_prune)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5e54444",
   "metadata": {},
   "outputs": [],
   "source": [
    "student.distilbert.prune_heads(heads_to_prune)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba8960ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments, Trainer, DataCollatorWithPadding\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./head_pruned_student\",\n",
    "    num_train_epochs=2,\n",
    "    per_device_train_batch_size=16,\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    learning_rate=3e-5,\n",
    "    weight_decay=0.01,\n",
    "    fp16=True,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"accuracy\",\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=student,\n",
    "    args=training_args,\n",
    "    train_dataset=train_ds,\n",
    "    eval_dataset=val_ds,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "\n",
    "trainer.train()\n",
    "trainer.save_model(\"./drive/MyDrive/head_pruned_student/best_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d358a081",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example latency measurement\n",
    "latency_ms = evaluate_latency(student, tokenizer, device)\n",
    "print(f\"Head-pruned student latency: {latency_ms:.2f} ms\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a157e000",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_params, nonzero_params, sparsity = count_parameters(student)\n",
    "print(f\"Total params: {total_params:,}\")\n",
    "print(f\"Non-zero params: {nonzero_params:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8933f51c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def folder_size_mb(path):\n",
    "    total = 0\n",
    "    for root, dirs, files in os.walk(path):\n",
    "        for f in files:\n",
    "            total += os.path.getsize(os.path.join(root, f))\n",
    "    return total / (1024**2)\n",
    "\n",
    "model_folder = \"./drive/MyDrive/head_pruned_student/best_model\"\n",
    "size_mb = folder_size_mb(model_folder)\n",
    "print(f\"Saved model folder size: {size_mb:.2f} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac462c00",
   "metadata": {},
   "outputs": [],
   "source": [
    "latency_ms = evaluate_latency(student, tokenizer, device, max_len=128, N=200)\n",
    "print(f\"Average batch=1 latency over 200 runs: {latency_ms:.2f} ms\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "063a9c4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = trainer.evaluate()\n",
    "print(res)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
